{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorboard_basic.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTFRKrO_H3Ck",
        "colab_type": "text"
      },
      "source": [
        "Graph and Loss visualization using Tensorboard. This example is using the MNIST database of handwritten digits (http://yann.lecun.com/exdb/mnist/).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBdAC70Ru3LD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "outputId": "43e2cc82-ab0c-4e5a-cb33-694f1af73683"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0825 17:24:47.492006 139680256632704 deprecation.py:323] From <ipython-input-1-d3a4abdef1a1>:6: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "W0825 17:24:47.493787 139680256632704 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "W0825 17:24:47.499038 139680256632704 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0825 17:24:47.805646 139680256632704 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "W0825 17:24:47.810702 139680256632704 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "W0825 17:24:47.866682 139680256632704 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: __init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50w-UdUUvIZA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#training hyperparameters\n",
        "learning_rate = 0.01\n",
        "training_epochs = 25\n",
        "batch_size=100\n",
        "display_step=1\n",
        "logs_path = '/tmp/tensorflow_logs/example/'\n",
        "\n",
        "#graph input\n",
        "x=tf.placeholder(tf.float32, [None, 784], name='InputData')\n",
        "y=tf.placeholder(tf.float32, [None, 10], name='LabelData')\n",
        "\n",
        "W=tf.Variable(tf.zeros([784, 10]), name='Weights')\n",
        "b=tf.Variable(tf.zeros([10]), name='bias')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6tGeHEMvwzt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# construct models encapsulating all ops into scopes,\n",
        "# making tensorboard's graph visualization more convenient\n",
        "with tf.name_scope('Model'):\n",
        "  #model\n",
        "  pred=tf.nn.softmax(tf.matmul(x,W)+b)\n",
        "  \n",
        "with tf.name_scope('Loss'):\n",
        "  #minimize error using cross entropy\n",
        "  cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices=1))\n",
        "  \n",
        "with tf.name_scope('SGD'):\n",
        "  # gradient descent\n",
        "  optimizer=tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
        "  \n",
        "with tf.name_scope('Accuracy'):\n",
        "  #accuracy\n",
        "  acc = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
        "  acc = tf.reduce_mean(tf.cast(acc,tf.float32))\n",
        "  \n",
        "#initialize variables\n",
        "init=tf.global_variables_initializer()\n",
        "\n",
        "#create summary to monitor cost tensor\n",
        "tf.summary.scalar(\"loss\", cost)\n",
        "\n",
        "#crate summarey to monitor accuracy tensor\n",
        "tf.summary.scalar(\"acc\", acc)\n",
        "\n",
        "#merge all summaries to single op\n",
        "merged_summary_op=tf.summary.merge_all()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "im_SEDiwxCep",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "outputId": "8f232043-58b8-4690-d2b2-2d72e289d2f4"
      },
      "source": [
        "#start training\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  \n",
        "  # op to write logs to tensorboard\n",
        "  summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
        "  \n",
        "  #training cycle\n",
        "  for epoch in range(training_epochs):\n",
        "    avg_cost=0.0\n",
        "    total_batch=int(mnist.train.num_examples/batch_size)\n",
        "    \n",
        "    #loop over all batches\n",
        "    for i in range(total_batch):\n",
        "      batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "      #run optimization op, cost op, and summary nodes\n",
        "      _, c, summary = sess.run([optimizer, cost, merged_summary_op],\n",
        "                              feed_dict={x:batch_xs, y:batch_ys})\n",
        "      #write every log at every iteration\n",
        "      summary_writer.add_summary(summary, epoch*total_batch+i)\n",
        "      #compute average loss\n",
        "      avg_cost += c/total_batch\n",
        "    \n",
        "    #display logs per epoch step\n",
        "    if (epoch+1)%display_step == 0:\n",
        "      print(\"epoch\",epoch, \"cost\",avg_cost)\n",
        "      \n",
        "  print(\"optimization finished!\")      \n",
        "  \n",
        "  #test model\n",
        "  #calculate accuracy\n",
        "  print(\"accuracy\",acc.eval({x:mnist.test.images, y:mnist.test.labels}))  "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0 cost 1.1839628335562622\n",
            "epoch 1 cost 0.6654106751355264\n",
            "epoch 2 cost 0.5528904629295525\n",
            "epoch 3 cost 0.4986241849985991\n",
            "epoch 4 cost 0.46550194491039576\n",
            "epoch 5 cost 0.4425898587703702\n",
            "epoch 6 cost 0.4255362641540439\n",
            "epoch 7 cost 0.4122198114611885\n",
            "epoch 8 cost 0.40142696800557026\n",
            "epoch 9 cost 0.3924021376263011\n",
            "epoch 10 cost 0.3848006728562441\n",
            "epoch 11 cost 0.3781524218483404\n",
            "epoch 12 cost 0.37242156638340485\n",
            "epoch 13 cost 0.36730999133803655\n",
            "epoch 14 cost 0.3627091372825882\n",
            "epoch 15 cost 0.3586131681095471\n",
            "epoch 16 cost 0.3548490467938507\n",
            "epoch 17 cost 0.3514516370946712\n",
            "epoch 18 cost 0.3483244306120005\n",
            "epoch 19 cost 0.34540796637535087\n",
            "epoch 20 cost 0.34275258985432694\n",
            "epoch 21 cost 0.34018086089329286\n",
            "epoch 22 cost 0.33795736968517337\n",
            "epoch 23 cost 0.3357051495530387\n",
            "epoch 24 cost 0.3336708156899975\n",
            "optimization finished!\n",
            "accuracy 0.9134\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}