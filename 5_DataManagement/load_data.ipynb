{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "load_data.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzx1j9ZY6Few",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Load and parse data with TensorFlow\n",
        "\n",
        "A TensorFlow example to build input pipelines for loading data efficiently.\n",
        "\n",
        "    Numpy Arrays\n",
        "    Images\n",
        "    CSV file\n",
        "    Custom data from a Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xg7U47ZI8y5H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import requests\n",
        "import string\n",
        "import tarfile\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCSHTCDl8_kW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create toy dataset (even and odd nmbers with respective labels of 0 and 1)\n",
        "evens=np.arange(0,100, step=2, dtype=np.int32)\n",
        "evens_label=np.zeros(50,dtype=np.int32)\n",
        "odds=np.arange(1,100,step=2,dtype=np.int32)\n",
        "odds_label=np.ones(50,dtype=np.int32)\n",
        "#concatenate arrays\n",
        "features=np.concatenate([evens,odds])\n",
        "labels=np.concatenate([evens_label, odds_label])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdagnX2s9iwN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "3d065acc-3d73-4391-d4be-fae5cb0762a2"
      },
      "source": [
        "with tf.Graph().as_default():\n",
        "  sess=tf.Session()\n",
        "  \n",
        "  #slice numpy arrays (each row becoming a record)\n",
        "  data =tf.data.Dataset.from_tensor_slices((features,labels))\n",
        "  #refill data indefinitely\n",
        "  data=data.repeat()\n",
        "  #shuffle data\n",
        "  data=data.shuffle(buffer_size=100)\n",
        "  #batch data (aggregate records together)\n",
        "  data=data.batch(batch_size=4)\n",
        "  #prefetch batch (pre-load batch for faster computation)\n",
        "  data=data.prefetch(buffer_size=1)\n",
        "  \n",
        "  #create an iterator over dataset\n",
        "  iterator=data.make_initializable_iterator()\n",
        "  #initialize iterator\n",
        "  sess.run(iterator.initializer)\n",
        "  \n",
        "  #get next data batch\n",
        "  d=iterator.get_next()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0826 12:53:57.257271 140463342319488 deprecation.py:323] From <ipython-input-5-d52c7b9345c6>:16: make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXMuL9c1_RPH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "cf98fceb-709f-41a7-bf72-af9a6a29b162"
      },
      "source": [
        "#display data\n",
        "for i in range(5):\n",
        "  x,y=sess.run(d)\n",
        "  print(x,y)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[59 10 78 31] [1 0 0 1]\n",
            "[62 18 34 47] [0 0 0 1]\n",
            "[74 60 48 99] [0 0 0 1]\n",
            "[28 55 69 23] [0 1 1 1]\n",
            "[38  1 70 87] [0 1 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPhVcXTw_bdu",
        "colab_type": "text"
      },
      "source": [
        "Load CSV files\n",
        "\n",
        "Build a pipeline from features stroed in CSV file. For this example, Titanic dataset will be used as a toy dataset stored in CSV format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRx8nknE_qjo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#download titanic dataset (in csv format)\n",
        "d=requests.get(\"https://raw.githubusercontent.com/tflearn/tflearn.github.io/master/resources/titanic_dataset.csv\")\n",
        "with open(\"titanic_dataset.csv\",\"wb\") as f:\n",
        "  f.write(d.content)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOpCQcSO_6jZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load titanic dataset\n",
        "#original features: survived, pclass, name, sex, age, sibsp, parch , ticket, fare\n",
        "#select specific colunmns : survived, plclass, name, sex, age, fare\n",
        "columns_to_use=[0,1,2,3,4,8]\n",
        "record_defaults=[tf.int32, tf.int32, tf.string, tf.string,tf.float32,tf.float32]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNE8nDYYARPK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.Graph().as_default():\n",
        "  #create tf session\n",
        "  sess=tf.Session()\n",
        "  \n",
        "  #load whole dataset file, slice each line\n",
        "  data=tf.data.experimental.CsvDataset(\"titanic_dataset.csv\",\n",
        "                                      record_defaults, header=True, select_cols=columns_to_use)\n",
        "  #refill data indefinitely\n",
        "  data=data.repeat()\n",
        "  #shuffle data\n",
        "  data=data.shuffle(buffer_size=1000)\n",
        "  #batch data (aggregate records toogetheer)\n",
        "  data=data.batch(batch_size=2)\n",
        "  #prefetch batch (pre-load batch for faster consumption)\n",
        "  data=data.prefetch(buffer_size=1)\n",
        "  \n",
        "  #create iterator over dataset\n",
        "  iterator=data.make_initializable_iterator()\n",
        "  #initialize iterator\n",
        "  sess.run(iterator.initializer)\n",
        "  \n",
        "  #get next data batch\n",
        "  d=iterator.get_next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsRbucWNBLFd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "f1f6e7f2-c1e2-4503-d0cb-e4f5bb5ed801"
      },
      "source": [
        "#displlay data\n",
        "for i in range(3):\n",
        "  survived, pclass, name, sex, age, fare=sess.run(d)\n",
        "  print(survived)\n",
        "  print(pclass)\n",
        "  print(name)\n",
        "  print(sex)\n",
        "  print(age)\n",
        "  print(fare)\n",
        "  print(\"\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0]\n",
            "[1 1]\n",
            "['Maioni, Miss. Roberta' 'Ross, Mr. John Hugo']\n",
            "['female' 'male']\n",
            "[16. 36.]\n",
            "[86.5   40.125]\n",
            "\n",
            "[1 1]\n",
            "[2 2]\n",
            "['Quick, Miss. Winifred Vera' 'Caldwell, Mr. Albert Francis']\n",
            "['female' 'male']\n",
            "[ 8. 26.]\n",
            "[26. 29.]\n",
            "\n",
            "[0 1]\n",
            "[1 3]\n",
            "['Futrelle, Mr. Jacques Heath' 'Albimona, Mr. Nassef Cassem']\n",
            "['male' 'male']\n",
            "[37. 26.]\n",
            "[53.1    18.7875]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcNhe0fFGS3R",
        "colab_type": "text"
      },
      "source": [
        "Load Images\n",
        "\n",
        "Build a data pipeline by loading images from disk. For this example, Oxford Flowers dataset will be used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYYfVyxOGbi6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#download Oxford 17 flowers dataset\n",
        "d=requests.get(\"http://www.robots.ox.ac.uk/~vgg/data/flowers/17/17flowers.tgz\")\n",
        "with open(\"17flowers.tgz\",\"wb\") as f:\n",
        "  f.write(d.content)\n",
        "#extract archive\n",
        "with tarfile.open(\"17flowers.tgz\") as t:\n",
        "  t.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2xNeUERVFN4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create a file to list all images path and their corresponding label\n",
        "with open('jpg/dataset.csv','w') as f:\n",
        "  c=0\n",
        "  for i in range(1360):\n",
        "    f.write(\"jpg/image_%04i.jpg,%i\\n\"%(i+1,c))\n",
        "    if (i+1)%80==0:\n",
        "      c+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfEFIulZVbah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.Graph().as_default():\n",
        "  \n",
        "  #load images\n",
        "  with open(\"jpg/dataset.csv\") as f:\n",
        "    dataset_file=f.read().splitlines()\n",
        "    \n",
        "  #create tf session\n",
        "  sess=tf.Session()\n",
        "  \n",
        "  #load whole dataset file, and slice each line\n",
        "  data=tf.data.Dataset.from_tensor_slices(dataset_file)\n",
        "  #refill data indefinitely\n",
        "  data=data.repeat()\n",
        "  #shuffle data\n",
        "  data=data.shuffle(buffer_size=1000)\n",
        "  \n",
        "  #load and pre process images\n",
        "  def load_image(path):\n",
        "    #read image from path\n",
        "    image=tf.io.read_file(path)\n",
        "    #decode jpeg image to array [0,255]\n",
        "    image=tf.image.decode_jpeg(image)\n",
        "    #resize image to a common size of 256x256\n",
        "    image=tf.image.resize(image,[256,256])\n",
        "    #rescale values to [-1,1]\n",
        "    image=1.0 - image/127.5\n",
        "    return image\n",
        "  \n",
        "  #decode each line from dataset file\n",
        "  def parse_records(line):\n",
        "    #file is in csv format : \"image_path, label_id\"\n",
        "    #tensorflow requires a default value, but it will never be used\n",
        "    image_path, image_label =tf.io.decode_csv(line, [\"\",0])\n",
        "    #apply function to load images\n",
        "    image=load_image(image_path)\n",
        "    return image, image_label\n",
        "  \n",
        "  #use 'map' to apply above functions in parallel\n",
        "  data=data.map(parse_records, num_parallel_calls=4)\n",
        "  \n",
        "  #batch data (aggreaget images-array together)\n",
        "  data=data.batch(batch_size=2)\n",
        "  #prefetch batch (pre-load batch for faster consumption)\n",
        "  data=data.prefetch(buffer_size=1)\n",
        "  \n",
        "  #create an iterator over dataset\n",
        "  iterator=data.make_initializable_iterator()\n",
        "  #initialize iterator\n",
        "  sess.run(iterator.initializer)\n",
        "  \n",
        "  #get next data batch\n",
        "  d=iterator.get_next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTnLSsc2X_p-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6b3ae284-e3ea-46e4-9375-010f48303ff7"
      },
      "source": [
        "#display data\n",
        "for i in range(1):\n",
        "  batch_x, batch_y=sess.run(d)\n",
        "  print(batch_x, batch_y)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[[ 0.84313726  0.9607843   0.9372549 ]\n",
            "   [ 0.9185049   1.          1.        ]\n",
            "   [ 0.8963235   0.9904412   0.9747549 ]\n",
            "   ...\n",
            "   [ 0.9973039   0.8915441   0.94509804]\n",
            "   [ 1.          0.95735294  1.        ]\n",
            "   [ 0.90931374  0.907598    0.9468137 ]]\n",
            "\n",
            "  [[ 0.88235295  1.          0.9992647 ]\n",
            "   [ 0.80053234  0.95592445  0.944874  ]\n",
            "   [ 0.8418237   0.98324525  0.97973347]\n",
            "   ...\n",
            "   [ 0.96867913  0.8577091   0.911263  ]\n",
            "   [ 0.9643038   0.9167509   0.9671607 ]\n",
            "   [ 0.91074216  0.9090265   0.9482422 ]]\n",
            "\n",
            "  [[ 0.6965686   0.92745095  0.94166666]\n",
            "   [ 0.7243489   0.9456725   0.9642195 ]\n",
            "   [ 0.660769    0.8752298   0.8972886 ]\n",
            "   ...\n",
            "   [ 0.813668    0.6873238   0.73633957]\n",
            "   [ 0.9454274   0.8942019   0.9290135 ]\n",
            "   [ 0.89244026  0.88084024  0.9200559 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.27941173  0.42843133  0.4732843 ]\n",
            "   [-0.15079093 -0.00177133  0.04308164]\n",
            "   [-0.3964423  -0.24779415 -0.2197305 ]\n",
            "   ...\n",
            "   [ 0.45693928  0.48899162  0.65089035]\n",
            "   [ 0.42541742  0.4257812   0.6143842 ]\n",
            "   [ 0.75019336  0.7244581   0.9395833 ]]\n",
            "\n",
            "  [[ 0.4198529   0.59313726  0.56740195]\n",
            "   [ 0.08705187  0.26033622  0.2346009 ]\n",
            "   [-0.39378834 -0.23577678 -0.24492955]\n",
            "   ...\n",
            "   [ 0.06020981  0.0326401   0.26646745]\n",
            "   [ 0.44299167  0.38335627  0.6711856 ]\n",
            "   [ 0.70911074  0.62226176  0.94460785]]\n",
            "\n",
            "  [[ 0.685049    0.8654412   0.8183823 ]\n",
            "   [ 0.336397    0.5167892   0.46973038]\n",
            "   [-0.2732805  -0.10416293 -0.12597668]\n",
            "   ...\n",
            "   [-0.30526197 -0.3458258  -0.08945322]\n",
            "   [ 0.46760106  0.40485597  0.7195619 ]\n",
            "   [ 0.64509803  0.55269605  0.89914215]]]\n",
            "\n",
            "\n",
            " [[[-0.34901965 -0.19215691 -0.20000005]\n",
            "   [-0.22061896 -0.08912385 -0.08670354]\n",
            "   [-0.43412995 -0.36721826 -0.32616425]\n",
            "   ...\n",
            "   [ 0.4370404   0.63311887  0.6880208 ]\n",
            "   [ 0.4823529   0.6627451   0.70980394]\n",
            "   [ 0.5914828   0.7561887   0.77971816]]\n",
            "\n",
            "  [[-0.26632977 -0.19295347 -0.21568632]\n",
            "   [-0.24917293 -0.2040143  -0.2164836 ]\n",
            "   [-0.39617252 -0.4000635  -0.37913823]\n",
            "   ...\n",
            "   [ 0.3678615   0.5490502   0.611397  ]\n",
            "   [ 0.37732768  0.5577198   0.60477865]\n",
            "   [ 0.46415436  0.62886024  0.65238965]]\n",
            "\n",
            "  [[-0.06678927 -0.12236524 -0.14748776]\n",
            "   [-0.26449227 -0.33649194 -0.3530339 ]\n",
            "   [-0.33768392 -0.42432463 -0.42873645]\n",
            "   ...\n",
            "   [ 0.37212008  0.52193624  0.57843137]\n",
            "   [ 0.36746174  0.52775586  0.57016075]\n",
            "   [ 0.44926393  0.5987752   0.62990195]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.4039216  -0.41176474 -0.34901965]\n",
            "   [-0.4035529  -0.41139603 -0.34865093]\n",
            "   [-0.41648078 -0.41648078 -0.3537357 ]\n",
            "   ...\n",
            "   [-0.38125002 -0.36605728 -0.37463248]\n",
            "   [-0.24279165 -0.21068168 -0.2156471 ]\n",
            "   [-0.38336945 -0.3127812  -0.32785475]]\n",
            "\n",
            "  [[-0.44246328 -0.45030642 -0.38756132]\n",
            "   [-0.42564058 -0.43348372 -0.37073863]\n",
            "   [-0.418998   -0.418998   -0.3562529 ]\n",
            "   ...\n",
            "   [-0.38569725 -0.37865067 -0.42025614]\n",
            "   [-0.28763413 -0.27433753 -0.3135532 ]\n",
            "   [-0.3477949  -0.30689347 -0.33906257]]\n",
            "\n",
            "  [[-0.4972427  -0.5050858  -0.44234073]\n",
            "   [-0.42481625 -0.4326594  -0.3699143 ]\n",
            "   [-0.40536165 -0.40536165 -0.34261656]\n",
            "   ...\n",
            "   [-0.21244204 -0.23597145 -0.30655968]\n",
            "   [-0.08878827 -0.11231768 -0.16121471]\n",
            "   [-0.13707042 -0.14491355 -0.17870641]]]] [ 1 11]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CI9nr0aaYJ5p",
        "colab_type": "text"
      },
      "source": [
        "Load data from a Generator\n",
        "\n",
        "Build a data pipeline from a custom generator.\n",
        "For this example, a toy generator yielding random string, vector and int is used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmSg-W9PYJRe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create dummy generator\n",
        "def generate_features():\n",
        "  #function to generate random string\n",
        "  def random_string(length):\n",
        "    return ''.join(random.choice(string.ascii_letters) for m in xrange(length))\n",
        "  #return random string, random vector and random int\n",
        "  yield random_string(4), np.random.uniform(size=4), random.randint(0,10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p846HemMY14c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.Graph().as_default():\n",
        "  sess=tf.Session()\n",
        "  \n",
        "  #create TF dataset from generator\n",
        "  data=tf.data.Dataset.from_generator(generate_features, output_types=(tf.string,\n",
        "                                                                      tf.float32,\n",
        "                                                                      tf.int32))\n",
        "  #refill data indefinitely\n",
        "  data=data.repeat()\n",
        "  #shuffle data\n",
        "  data=data.shuffle(buffer_size=100)\n",
        "  #batch data (aggregate records together)\n",
        "  data=data.batch(batch_size=4)\n",
        "  #prefetch batch (pre-load batch for faster consumption)\n",
        "  data=data.prefetch(buffer_size=1)\n",
        "  \n",
        "  #create an iterator over dataset\n",
        "  iterator=data.make_initializable_iterator()\n",
        "  #initialize the iterator\n",
        "  sess.run(iterator.initializer)\n",
        "  \n",
        "  #get next data batch\n",
        "  d=iterator.get_next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpixm2sqZh6G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "9494edd3-493a-4e4f-dd60-8951d3fad83f"
      },
      "source": [
        "#display data\n",
        "for i in range(5):\n",
        "  batch_str, batch_vector, batch_int=sess.run(d)\n",
        "  print(batch_str, batch_vector, batch_int)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['arbW' 'pScG' 'KZIr' 'zNRe'] [[0.27371687 0.04913669 0.25907984 0.84514105]\n",
            " [0.46897408 0.19587737 0.6731533  0.7314421 ]\n",
            " [0.11443488 0.90311354 0.8957534  0.1712661 ]\n",
            " [0.8081347  0.09573816 0.14854978 0.623093  ]] [3 6 5 4]\n",
            "['LbuL' 'ghlr' 'UsZn' 'RmWl'] [[0.92380947 0.8743449  0.5858188  0.45991743]\n",
            " [0.19383323 0.47632334 0.5417587  0.34051272]\n",
            " [0.0375283  0.3907353  0.09617063 0.24519591]\n",
            " [0.37095007 0.10410413 0.32756004 0.5564047 ]] [3 9 8 6]\n",
            "['KoMw' 'qFrf' 'OvIr' 'vCvd'] [[0.03106382 0.2384225  0.9419692  0.09193267]\n",
            " [0.3254956  0.89814734 0.39259553 0.06813686]\n",
            " [0.6031087  0.36409938 0.19767705 0.01070746]\n",
            " [0.5872436  0.22545953 0.96978426 0.5304217 ]] [ 1 10  0  1]\n",
            "['lZeL' 'mjsy' 'xJRC' 'rQHn'] [[0.20834456 0.42881402 0.26402912 0.6814654 ]\n",
            " [0.6332764  0.5871682  0.3497198  0.28776738]\n",
            " [0.22815652 0.7827053  0.86866796 0.00186023]\n",
            " [0.72032577 0.2193191  0.5344611  0.7099987 ]] [10  0  7  2]\n",
            "['aZbi' 'yulU' 'BbvR' 'LcVX'] [[0.42651826 0.6934289  0.17446402 0.59790736]\n",
            " [0.6843022  0.71087843 0.07723168 0.94119847]\n",
            " [0.62088567 0.7848251  0.85074747 0.83964187]\n",
            " [0.30788586 0.38924462 0.58786845 0.9068394 ]] [3 9 0 3]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}